{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 1: Verificar versión de Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:14:39,585 - INFO - \n",
      "    **********************************************\n",
      "    ** Versión de Python compatible **\n",
      "    **********************************************\n",
      "    Python 3.10.12 detectado correctamente.\n",
      "    Todas las funcionalidades deberían operar sin problemas.\n",
      "    **********************************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import sys  # Acceder a la información de la versión de Python.\n",
    "import os  # Manejo de rutas, archivos y operaciones del sistema.\n",
    "import logging  # Configuración y uso de logs para monitorear la ejecución.\n",
    "\n",
    "# Configurar la variable de entorno para desactivar la paralelización de tokenizadores y evitar advertencias\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "\n",
    "# Definir la versión requerida de Python\n",
    "REQUIRED_VERSION = (3, 10, 12)\n",
    "current_version = sys.version_info\n",
    "\n",
    "# Validar la versión de Python\n",
    "if (current_version.major, current_version.minor, current_version.micro) != REQUIRED_VERSION:\n",
    "    logging.warning(\"\"\"\n",
    "    **********************************************\n",
    "    ** Advertencia: Versión de Python no compatible **\n",
    "    **********************************************\n",
    "    Este chatbot está optimizado para Python 3.10.12.\n",
    "    La versión actual es Python {}.{}.{}.\n",
    "    Algunas funcionalidades pueden no funcionar correctamente.\n",
    "    **********************************************\n",
    "    \"\"\".format(current_version.major, current_version.minor, current_version.micro))\n",
    "else:\n",
    "    logging.info(\"\"\"\n",
    "    **********************************************\n",
    "    ** Versión de Python compatible **\n",
    "    **********************************************\n",
    "    Python 3.10.12 detectado correctamente.\n",
    "    Todas las funcionalidades deberían operar sin problemas.\n",
    "    **********************************************\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 2: Instalación de Paquetes Necesarios**\n",
    "Se instalan las bibliotecas necesarias para que el chatbot funcione correctamente.\n",
    "\n",
    "- **Transformers (`transformers`)**: Para el procesamiento de lenguaje natural.\n",
    "- **Sentence Transformers (`sentence_transformers`)**: Para crear embeddings eficientes de texto.\n",
    "- **HNSWlib (`hnswlib`)**: Realiza búsquedas rápidas de vecinos más cercanos.\n",
    "- **Numpy (`numpy<2.0`)**: Utiliza una versión compatible para operaciones matemáticas.\n",
    "- **PyPDF2 (`PyPDF2`)**: Manejo y extracción de texto desde archivos PDF.\n",
    "- **Dotenv (`python-dotenv`)**: Gestiona variables de entorno desde un archivo `.env`.\n",
    "- **Tenacity (`tenacity`)**: Manejo de reintentos con lógica exponencial.\n",
    "- **Llama Index (`llama-index` y extensiones para Gemini)**: Proporciona integración con el modelo Gemini.\n",
    "- **Tqdm (`tqdm`)**: Barra de progreso visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de bibliotecas necesarias\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 2: Importar Librerías y Configurar Logging**\n",
    "Se importan las librerías necesarias y se configura un sistema de logs para monitorear todo el flujo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:18:14,278 - INFO - Librerías importadas correctamente.\n",
      "2024-12-06 20:18:14,286 - INFO - Variables de entorno cargadas desde el archivo .env.\n"
     ]
    }
   ],
   "source": [
    "# Importación de librerías esenciales para el funcionamiento del chatbot.\n",
    "import os  # Manejo de rutas, archivos y operaciones del sistema.\n",
    "import json  # Manipulación de datos en formato JSON.\n",
    "import logging  # Configuración y uso de logs para monitorear la ejecución.\n",
    "import hnswlib  # Búsqueda eficiente de similitud utilizando índices de alta dimensionalidad.\n",
    "from sentence_transformers import SentenceTransformer, util  # Embeddings de texto y cálculo de similitud.\n",
    "import numpy as np  # Operaciones matemáticas avanzadas y estructuras de datos.\n",
    "from dotenv import load_dotenv  # Carga de variables de entorno desde un archivo `.env`.\n",
    "from PyPDF2 import PdfReader  # Extracción de texto de documentos PDF.\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type  # Gestión de reintentos en funciones críticas.\n",
    "from llama_index.llms.gemini import Gemini  # Interfaz para el modelo de lenguaje Gemini.\n",
    "from llama_index.core.llms import ChatMessage  # Estructuras de mensajes para interacción con LLMs.\n",
    "import time  # Manejo de tiempos y medición de duración de procesos.\n",
    "import hashlib  # Generación de hashes únicos para almacenamiento en caché.\n",
    "\n",
    "# Configuración de logging para imprimir todo en consola\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]  # Solo consola\n",
    ")\n",
    "\n",
    "logging.info(\"Librerías importadas correctamente.\")  # Mensaje de log para confirmar importación\n",
    "\n",
    "# Cargar variables de entorno desde un archivo .env\n",
    "load_dotenv()\n",
    "logging.info(\"Variables de entorno cargadas desde el archivo .env.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 3: Cargar Documentos**\n",
    "Este paso carga documentos desde un archivo o un directorio. Soporta formatos .txt, .json y .pdf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:14:39,639 - INFO - Iniciando carga desde el directorio: data.\n",
      "2024-12-06 20:14:39,651 - INFO - Archivo 'resumenes_lupus.json' cargado correctamente.\n",
      "2024-12-06 20:14:39,654 - INFO - Archivo 'resumenes_duchenne.json' cargado correctamente.\n",
      "2024-12-06 20:14:39,656 - INFO - Archivo 'resumenes_pompe.json' cargado correctamente.\n",
      "2024-12-06 20:14:39,658 - INFO - Archivo 'resumenes_becker.json' cargado correctamente.\n",
      "2024-12-06 20:14:39,659 - INFO - Archivo 'resumenes_glycogen storage disease.json' cargado correctamente.\n",
      "2024-12-06 20:14:39,664 - INFO - Archivo 'resumenes_myotonic dystrophy.json' cargado correctamente.\n",
      "2024-12-06 20:14:39,666 - INFO - 6 documentos cargados.\n",
      "2024-12-06 20:14:39,668 - INFO - Se cargaron 6 documentos exitosamente.\n"
     ]
    }
   ],
   "source": [
    "def load_documents(source, is_directory=False):\n",
    "    \"\"\"\n",
    "    Carga documentos desde un archivo o un directorio. Soporta .txt, .json y .pdf.\n",
    "    Además, divide los archivos .txt en unidades usando un delimitador específico.\n",
    "    \"\"\"\n",
    "    loaded_files = []\n",
    "\n",
    "    # Verificar si la ruta existe\n",
    "    if not os.path.exists(source):\n",
    "        logging.error(f\"La fuente '{source}' no existe.\")\n",
    "        raise FileNotFoundError(f\"La fuente '{source}' no se encontró.\")\n",
    "\n",
    "    if is_directory:\n",
    "        logging.info(f\"Iniciando carga desde el directorio: {source}.\")\n",
    "        for filename in os.listdir(source):\n",
    "            filepath = os.path.join(source, filename)\n",
    "            if os.path.isfile(filepath) and filepath.endswith(('.txt', '.json', '.pdf')):\n",
    "                content = extract_content(filepath)\n",
    "                if content:\n",
    "                    loaded_files.append({\"filename\": filename, \"content\": content})\n",
    "                    logging.info(f\"Archivo '{filename}' cargado correctamente.\")\n",
    "    else:\n",
    "        logging.info(f\"Iniciando carga del archivo: {source}.\")\n",
    "        content = extract_content(source)\n",
    "        if content:\n",
    "            loaded_files.append({\"filename\": os.path.basename(source), \"content\": content})\n",
    "            logging.info(f\"Archivo '{os.path.basename(source)}' cargado correctamente.\")\n",
    "\n",
    "    logging.info(f\"{len(loaded_files)} documentos cargados.\")\n",
    "    return loaded_files\n",
    "\n",
    "def extract_content(filepath):\n",
    "    \"\"\"\n",
    "    Extrae el contenido del archivo según su tipo (.txt, .json, .pdf).\n",
    "    Si el archivo es .txt, lo divide en unidades por el delimitador '\\n-----\\n'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if filepath.endswith('.txt'):\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            units = content.split(\"\\n-----\\n\")\n",
    "            return units  # Devolver una lista de unidades\n",
    "        elif filepath.endswith('.json'):\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            # OPORTUNIDAD DE MEJORA: Validar la estructura del JSON antes de retornarlo\n",
    "            return data\n",
    "        elif filepath.endswith('.pdf'):\n",
    "            reader = PdfReader(filepath)\n",
    "            return ''.join(page.extract_text() or '' for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al extraer contenido de '{filepath}': {e}\")\n",
    "        return None\n",
    "\n",
    "ruta_fuente = 'data' # Ejemplo usando un directorio\n",
    "documentos = load_documents(ruta_fuente, is_directory=True)\n",
    "logging.info(f\"Se cargaron {len(documentos)} documentos exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 4: Configurar la Clave API de Gemini**\n",
    "Configura la conexión con el modelo de lenguaje Gemini usando la clave API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:14:40,808 - INFO - Gemini configurado correctamente.\n"
     ]
    }
   ],
   "source": [
    "gemini_llm = None\n",
    "\n",
    "def configure_gemini():\n",
    "    \"\"\"\n",
    "    Configura la instancia de Gemini usando la clave API.\n",
    "    \"\"\"\n",
    "    global gemini_llm\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        logging.error(\"La clave API de Gemini no está configurada.\")\n",
    "        raise EnvironmentError(\"Configura GEMINI_API_KEY en tu archivo .env.\")\n",
    "    gemini_llm = Gemini(api_key=api_key)\n",
    "    logging.info(\"Gemini configurado correctamente.\")\n",
    "\n",
    "configure_gemini()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASO 5\n",
    "Configurar el modelo de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:14:40,834 - INFO - Use pytorch device_name: mps\n",
      "2024-12-06 20:14:40,835 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\" \n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "def doc_enfermedad(pregunta):\n",
    "    \"\"\"\n",
    "    Identifica el índice del documento más relevante para la enfermedad en la pregunta.\n",
    "    Se basa en la máxima similitud entre el embedding de la pregunta y los nombres de los archivos.\n",
    "    OPORTUNIDAD DE MEJORA: Si el nombre del archivo no es representativo, esto podría fallar.\n",
    "    Mejorar usando embeddings del contenido en el futuro.\n",
    "    \"\"\"\n",
    "    if not documentos:\n",
    "        logging.warning(\"No se encontraron documentos. Devolviendo índice 0 por defecto.\")\n",
    "        return 0\n",
    "    preg_embedding = model.encode(pregunta)\n",
    "    archivos = [documentos[i]['filename'] for i in range(len(documentos))]\n",
    "    doc_filenames_embeddings = [model.encode(name) for name in archivos]\n",
    "    similarities = [util.cos_sim(preg_embedding, doc_emb).item() for doc_emb in doc_filenames_embeddings]\n",
    "    max_index = similarities.index(max(similarities))\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASO 6\n",
    "Crear clases para documentos e índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, text, metadata=None):\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata or {}\n",
    "    \n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"Título: {self.metadata.get('Title', 'N/A')}\\n\"\n",
    "            f\"Resumen: {self.metadata.get('Summary', 'N/A')}\\n\"\n",
    "            f\"Tipo de Estudio: {self.metadata.get('StudyType', 'N/A')}\\n\"\n",
    "            f\"Paises donde se desarrolla el estudio: {self.metadata.get('Countries', 'N/A')}\\n\"\n",
    "            f\"Fase en que se encuentra el estudio: {self.metadata.get('Phases', 'N/A')}\\n\"\n",
    "            f\"Identificación en ClinicaTrial: {self.metadata.get('IDestudio', 'N/A')}.\\n\\n\"\n",
    "        )\n",
    "\n",
    "class HNSWIndex:\n",
    "    def __init__(self, embeddings, metadata=None, space='cosine', ef_construction=200, M=16):\n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = hnswlib.Index(space=space, dim=self.dimension)\n",
    "        self.index.init_index(max_elements=embeddings.shape[0], ef_construction=ef_construction, M=M)\n",
    "        self.index.add_items(embeddings, np.arange(embeddings.shape[0]))\n",
    "        self.index.set_ef(50)  # Parámetro ef para consultas\n",
    "        self.metadata = metadata or []\n",
    "    \n",
    "    def similarity_search(self, query_vector, k=5):\n",
    "        labels, distances = self.index.knn_query(query_vector, k=k)\n",
    "        return [(self.metadata[i], distances[0][j]) for j, i in enumerate(labels[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASO 7\n",
    "Se procesan los documentos y se crea un índice HNSWlib para cada conjunto de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 39/39 [01:33<00:00,  2.40s/it]\n",
      "Batches: 100%|██████████| 12/12 [00:25<00:00,  2.13s/it]\n",
      "Batches: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\n",
      "Batches: 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n",
      "Batches: 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "2024-12-06 20:17:09,022 - INFO - Índices HNSWlib creados para todos los documentos.\n"
     ]
    }
   ],
   "source": [
    "def desdobla_doc(data2):\n",
    "    \"\"\"\n",
    "    Desdobla el contenido del documento en varios Documents con metadatos.\n",
    "    Maneja JSON (asumiendo estructura de ensayos clínicos) o texto/PDF genérico.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    summaries = []\n",
    "    contenido = data2['content']\n",
    "    \n",
    "    # OPORTUNIDAD DE MEJORA: Validar la estructura en caso de JSON\n",
    "    if isinstance(contenido, list):\n",
    "        for entry in contenido:\n",
    "            if isinstance(entry, dict):\n",
    "                nctId = entry.get(\"IDestudio\", \"\")\n",
    "                briefTitle = entry.get(\"Title\", \"\")\n",
    "                summary = entry.get(\"Summary\", \"\")\n",
    "                studyType = entry.get(\"StudyType\", \"\")\n",
    "                country = entry.get(\"Countries\", \"\")\n",
    "                overallStatus = entry.get(\"OverallStatus\", \"\")\n",
    "                conditions = entry.get(\"Conditions\", \"\")\n",
    "                phases = entry.get(\"Phases\", \"\")\n",
    "\n",
    "                # Texto del documento en inglés (Mantener la consistencia de idioma del resumen interno)\n",
    "                Summary = (\n",
    "                    f\"The study titled '{briefTitle}', of type '{studyType}', \"\n",
    "                    f\"investigates the condition(s): {conditions}. \"\n",
    "                    f\"Brief summary: {summary}. \"\n",
    "                    f\"Current status: {overallStatus}, taking place in {country}. \"\n",
    "                    f\"The study is classified under: {phases} phase. \"\n",
    "                    f\"For more info, search {nctId} on ClinicalTrials.\"\n",
    "                )\n",
    "                metadata = {\n",
    "                    \"Title\": briefTitle,\n",
    "                    \"Summary\": Summary,\n",
    "                    \"StudyType\": studyType,\n",
    "                    \"Countries\": country,\n",
    "                    \"Phases\": phases,\n",
    "                    \"IDestudio\": nctId\n",
    "                }\n",
    "                doc = Document(Summary, metadata)\n",
    "                documents.append(doc)\n",
    "                summaries.append(Summary)\n",
    "            else:\n",
    "                # Si no es dict, tratamos la entrada como texto genérico\n",
    "                texto = str(entry)\n",
    "                metadata = {\"Summary\": texto}\n",
    "                doc = Document(texto, metadata)\n",
    "                documents.append(doc)\n",
    "                summaries.append(texto)\n",
    "    else:\n",
    "        # Texto genérico (PDF o TXT)\n",
    "        texto = str(contenido)\n",
    "        metadata = {\"Summary\": texto}\n",
    "        doc = Document(texto, metadata)\n",
    "        documents.append(doc)\n",
    "        summaries.append(texto)\n",
    "\n",
    "    if documents:\n",
    "        embeddings = model.encode([doc.page_content for doc in documents], show_progress_bar=True)\n",
    "        embeddings = np.array(embeddings).astype(np.float32)\n",
    "        vector_store = HNSWIndex(embeddings, metadata=[doc.metadata for doc in documents])\n",
    "    else:\n",
    "        vector_store = None\n",
    "\n",
    "    return documents, vector_store\n",
    "\n",
    "trozos_archivos = []\n",
    "index_archivos = []\n",
    "for i in range(len(documentos)):\n",
    "    trozos, index = desdobla_doc(documentos[i])\n",
    "    trozos_archivos.append(trozos)\n",
    "    index_archivos.append(index)\n",
    "\n",
    "logging.info(\"Índices HNSWlib creados para todos los documentos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 8: Traducir Preguntas y Respuestas**\n",
    "Traduce preguntas y respuestas entre idiomas según sea necesario utilizando Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traducir(texto, idioma_destino):\n",
    "    \"\"\"\n",
    "    Traduce texto al idioma especificado usando el modelo Gemini.\n",
    "    En caso de error, se devuelve el texto original.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    mensajes = [\n",
    "        ChatMessage(role=\"system\", content=\"Actúa como un traductor.\"),\n",
    "        ChatMessage(role=\"user\", content=f\"Por favor, traduce este texto al {idioma_destino}: {texto}\")\n",
    "    ]\n",
    "    try:\n",
    "        respuesta = gemini_llm.chat(mensajes)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logging.info(f\"Traducción completada en {elapsed_time:.2f} segundos.\")\n",
    "        return respuesta.message.content.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al traducir: {e}\")\n",
    "        return texto  # fallback\n",
    "\n",
    "def generate_embedding(texto):\n",
    "    \"\"\"\n",
    "    Genera un embedding para la pregunta utilizando el modelo de embeddings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        embedding = model.encode([texto])\n",
    "        logging.info(f\"Embedding generado para el texto: {texto}\")\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al generar el embedding: {e}\")\n",
    "        return np.zeros((1, 384)) # Dimensión aproximada fallback para all-MiniLM-L6-v2\n",
    "\n",
    "\n",
    "def obtener_contexto(pregunta, index, trozos, top_k=50):\n",
    "    \"\"\"\n",
    "    Recupera los trozos de texto más relevantes para responder la pregunta.\n",
    "    Traduce la pregunta al inglés antes de buscar en el índice.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Traducir la pregunta al inglés\n",
    "        pregunta_en_ingles = traducir(pregunta, \"inglés\")\n",
    "        logging.info(f\"Pregunta traducida al inglés: {pregunta_en_ingles}\")\n",
    "\n",
    "        # Generar embedding de la pregunta traducida\n",
    "        pregunta_emb = generate_embedding(pregunta_en_ingles)\n",
    "        logging.info(\"Embedding generado para la pregunta.\")\n",
    "\n",
    "        # Buscar en el índice\n",
    "        results = index.similarity_search(pregunta_emb, k=top_k)\n",
    "        texto = \"\"\n",
    "        for entry in results:\n",
    "            resum = entry[0][\"Summary\"]\n",
    "            texto += resum + \"\\n\"\n",
    "\n",
    "        logging.info(\"Contexto relevante recuperado para la pregunta.\")\n",
    "        return texto\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al obtener el contexto: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 9: Generar Respuestas**\n",
    "Genera respuestas utilizando el modelo Gemini y el contexto proporcionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_pregunta(pregunta):\n",
    "    \"\"\"\n",
    "    Clasifica la pregunta en categorías.\n",
    "    OPORTUNIDAD DE MEJORA: Usar un modelo de clasificación semántica en lugar de palabras clave.\n",
    "    \"\"\"\n",
    "    categorias = {\n",
    "        \"tratamiento\": [\"tratamiento\", \"medicación\", \"cura\", \"terapia\", \"fármaco\"],\n",
    "        \"ensayo\": [\"ensayo\", \"estudio\", \"prueba\", \"investigación\", \"trial\"],\n",
    "        \"resultado\": [\"resultado\", \"efectividad\", \"resultados\", \"éxito\", \"fracaso\"],\n",
    "        \"prevención\": [\"prevención\", \"previene\", \"evitar\", \"reducción de riesgo\"]\n",
    "    }\n",
    "    for categoria, palabras in categorias.items():\n",
    "        if any(palabra in pregunta.lower() for palabra in palabras):\n",
    "            return categoria\n",
    "    return \"general\"\n",
    "\n",
    "def generar_prompt(categoria, pregunta):\n",
    "    \"\"\"\n",
    "    Genera un prompt específico basado en la categoría de la pregunta.\n",
    "    \"\"\"\n",
    "    prompts = {\n",
    "        \"tratamiento\": f\"Proporciona información sobre tratamientos en ensayos clínicos relacionados con: {pregunta}.\",\n",
    "        \"ensayo\": f\"Describe los ensayos clínicos actuales relacionados con: {pregunta}.\",\n",
    "        \"resultado\": f\"Explica los resultados más recientes de ensayos clínicos sobre: {pregunta}.\",\n",
    "        \"prevención\": f\"Ofrece información sobre prevención y ensayos clínicos para: {pregunta}.\"\n",
    "    }\n",
    "    return prompts.get(categoria, \"Por favor, responde la pregunta sobre ensayos clínicos.\")\n",
    "\n",
    "\n",
    "def es_saludo(pregunta):\n",
    "    saludos = [\"hola\", \"buen día\", \"buenas\", \"cómo estás\", \"cómo te llamas\", \"qué tal\", \"estás bien\", \"buenas tardes\", \"buenas noches\"]\n",
    "    return any(saludo in pregunta.lower() for saludo in saludos)\n",
    "\n",
    "def responder_saludo():\n",
    "    saludos_respuestas = [\n",
    "        \"¡Hola! Estoy para ayudarte con información sobre ensayos clínicos. ¿En qué puedo asistirte hoy?\",\n",
    "        \"¡Buenas! Tenés alguna pregunta sobre ensayos clínicos en enfermedades neuromusculares?\",\n",
    "        \"¡Hola! ¿Cómo puedo ayudarte con tus consultas sobre ensayos clínicos?\"\n",
    "    ]\n",
    "    import random\n",
    "    return random.choice(saludos_respuestas)\n",
    "\n",
    "def generar_respuesta(pregunta, contexto, prompt_especifico):\n",
    "    \"\"\"\n",
    "    Genera una respuesta usando el contexto proporcionado y un prompt específico.\n",
    "    Primero genera la respuesta en inglés, luego la traduce al español.\n",
    "    OPORTUNIDAD DE MEJORA: Si el usuario pregunta en inglés, devolver directamente en inglés.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    mensajes = [\n",
    "        ChatMessage(role=\"system\", content=\"Eres un experto médico.\"),\n",
    "        ChatMessage(role=\"user\", content=f\"{prompt_especifico}\\nContexto: {contexto}\\nPregunta: {pregunta}\")\n",
    "    ]\n",
    "    try:\n",
    "        respuesta = gemini_llm.chat(mensajes)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logging.info(f\"Respuesta generada en inglés en {elapsed_time:.2f} segundos.\")\n",
    "\n",
    "        # Traducir la respuesta al español\n",
    "        respuesta_en_espanol = traducir(respuesta.message.content, \"español\")\n",
    "        logging.info(\"Respuesta traducida al español.\")\n",
    "        return respuesta_en_espanol\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al generar la respuesta: {e}\")\n",
    "        return \"Lo siento, ocurrió un error al generar la respuesta.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 10: Función Principal para Responder Preguntas**\n",
    "Integra todos los pasos previos para traducir, recuperar contexto y generar respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_hash(pregunta):\n",
    "    return hashlib.sha256(pregunta.encode('utf-8')).hexdigest()\n",
    "\n",
    "def obtener_respuesta_cacheada(pregunta):\n",
    "    hash_pregunta = generar_hash(pregunta)\n",
    "    archivo_cache = f\"cache/{hash_pregunta}.json\"\n",
    "    if os.path.exists(archivo_cache):\n",
    "        try:\n",
    "            with open(archivo_cache, \"r\", encoding='utf-8') as f:\n",
    "                datos = json.load(f)\n",
    "                return datos.get(\"respuesta\", None)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al leer el caché: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def guardar_respuesta_cacheada(pregunta, respuesta):\n",
    "    hash_pregunta = generar_hash(pregunta)\n",
    "    archivo_cache = f\"cache/{hash_pregunta}.json\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(archivo_cache), exist_ok=True)\n",
    "        with open(archivo_cache, \"w\", encoding='utf-8') as f:\n",
    "            json.dump({\"pregunta\": pregunta, \"respuesta\": respuesta}, f, ensure_ascii=False, indent=4)\n",
    "        logging.info(f\"Respuesta cacheada para la pregunta: '{pregunta}'\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al guardar la respuesta en caché: {e}\")\n",
    "\n",
    "def responder_pregunta(pregunta, index, trozos):\n",
    "    \"\"\"\n",
    "    Integra todos los pasos: categorización, traducción, recuperación de contexto y generación de respuestas.\n",
    "    Incluye manejo de caché.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if index is None or not trozos:\n",
    "            logging.warning(\"No se pudieron generar índices o no hay trozos. Devolviendo respuesta genérica.\")\n",
    "            return \"No se encontró información para responder tu pregunta.\"\n",
    "\n",
    "        # Verificar caché\n",
    "        respuesta_cacheada = obtener_respuesta_cacheada(pregunta)\n",
    "        if respuesta_cacheada:\n",
    "            logging.info(f\"Respuesta obtenida del caché: '{pregunta}'\")\n",
    "            return respuesta_cacheada\n",
    "\n",
    "        categoria = categorizar_pregunta(pregunta)\n",
    "        logging.info(f\"Categoría de la pregunta: {categoria}\")\n",
    "\n",
    "        prompt_especifico = generar_prompt(categoria, pregunta)\n",
    "        logging.info(f\"Prompt específico: {prompt_especifico}\")\n",
    "\n",
    "        contexto = obtener_contexto(pregunta, index, trozos)\n",
    "        if not contexto.strip():\n",
    "            logging.warning(\"No se encontró contexto relevante.\")\n",
    "            respuesta = \"No pude encontrar información relevante para responder tu pregunta.\"\n",
    "            guardar_respuesta_cacheada(pregunta, respuesta)\n",
    "            return respuesta\n",
    "\n",
    "        respuesta = generar_respuesta(pregunta, contexto, prompt_especifico)\n",
    "\n",
    "        guardar_respuesta_cacheada(pregunta, respuesta)\n",
    "        return respuesta\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el proceso de responder pregunta: {e}\")\n",
    "        return \"Ocurrió un error al procesar tu pregunta.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 11: Interfaz CLI**\n",
    "Proporciona una interfaz interactiva para que los usuarios puedan hacer preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenido al Chatbot de Ensayos Clínicos\n",
      "Conversemos sobre Ensayos Clínicos\n",
      " de enfermedades neuromusculares: Distrofia Muscular de Duchenne o de Becker, Enfermedad de Pompe, Distrofia Miotónica, etc.\n",
      "Escribí tu pregunta, indicando claramente la enfermedad sobre la que quieres información de ensayos clínicos. Escribe 'salir' para terminar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s]\n",
      "2024-12-06 20:18:24,954 - INFO - Categoría de la pregunta: ensayo\n",
      "2024-12-06 20:18:24,955 - INFO - Prompt específico: Describe los ensayos clínicos actuales relacionados con: ¿Cuantos ensayos clínicos están activos actualmente para la Distrofia Muscular de Duchenne?.\n",
      "2024-12-06 20:18:26,432 - INFO - Traducción completada en 1.47 segundos.\n",
      "2024-12-06 20:18:26,432 - INFO - Pregunta traducida al inglés: How many clinical trials are currently active for Duchenne Muscular Dystrophy?\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "2024-12-06 20:18:26,775 - INFO - Embedding generado para el texto: How many clinical trials are currently active for Duchenne Muscular Dystrophy?\n",
      "2024-12-06 20:18:26,776 - INFO - Embedding generado para la pregunta.\n",
      "2024-12-06 20:18:26,777 - INFO - Contexto relevante recuperado para la pregunta.\n",
      "2024-12-06 20:18:32,763 - INFO - Respuesta generada en inglés en 5.98 segundos.\n",
      "2024-12-06 20:18:38,768 - INFO - Traducción completada en 6.00 segundos.\n",
      "2024-12-06 20:18:38,769 - INFO - Respuesta traducida al español.\n",
      "2024-12-06 20:18:38,771 - INFO - Respuesta cacheada para la pregunta: '¿Cuantos ensayos clínicos están activos actualmente para la Distrofia Muscular de Duchenne?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: Basándome en la información proporcionada, hay **11 ensayos clínicos activos actualmente** para la Distrofia Muscular de Duchenne. Estos son:\n",
      "\n",
      "* **El Registro de Duchenne (NCT02069756):** RECLUTANDO\n",
      "* **Estudio a largo plazo y de extensión de DS-5141b en pacientes con Distrofia Muscular de Duchenne (NCT04433234):** ACTIVO, NO RECLUTANDO\n",
      "* **Registro de evaluación en video de la Distrofia Muscular de Duchenne (NCT05712447):** ACTIVO, NO RECLUTANDO\n",
      "* **Estudio de SRP-4045 (Casimersen) y SRP-4053 (Golodirsen) en participantes con Distrofia Muscular de Duchenne (DMD) (NCT02500381):** ACTIVO, NO RECLUTANDO\n",
      "* **AFFINITY DUCHENNE: Terapia génica RGX-202 en participantes con Distrofia Muscular de Duchenne (DMD) (NCT05693142):** RECLUTANDO\n",
      "* **Un Estudio de Fase 3 de TAS-205 en pacientes con Distrofia Muscular de Duchenne (REACH-DMD) (NCT04587908):** ACTIVO, NO RECLUTANDO\n",
      "* **Un Estudio de la terapia génica SGT-003 en la Distrofia Muscular de Duchenne (INSPIRE DUCHENNE) (NCT06138639):** RECLUTANDO\n",
      "* **Un Estudio Observacional que Compara Delandistrogene Moxeparvovec con el Estándar de Cuidado en Participantes con Distrofia Muscular de Duchenne (NCT06270719):** RECLUTANDO\n",
      "* **Un Estudio de PGN-EDO51 en Participantes con Distrofia Muscular de Duchenne Aptos para el Tratamiento de Salto del Exón 51 (NCT06079736):** RECLUTANDO\n",
      "* **Estudio para Evaluar la Seguridad y Eficacia de PF-06939926 para el Tratamiento de la Distrofia Muscular de Duchenne (NCT04281485):** ACTIVO, NO RECLUTANDO\n",
      "* **Hidroterapia en la Distrofia Muscular de Duchenne (DMD) (NCT06445985):** RECLUTANDO\n",
      "* **Un Estudio de CAP-1002 en Pacientes Ambulatorios y No Ambulatorios con Distrofia Muscular de Duchenne (NCT05126758):** RECLUTANDO\n",
      "* **NS-089/NCNP-02-201 en Niños con Distrofia Muscular de Duchenne (DMD) (NCT05996003):** RECLUTANDO\n",
      "* **Estudio de Seguridad, Tolerabilidad, Farmacodinámica, Eficacia y Farmacocinética de DYNE-251 en Participantes con Distrofia Muscular de Duchenne Aptos para el Salto del Exón 51 (NCT05524883):** RECLUTANDO\n",
      "* **Un Estudio Abierto para Evaluar la Eficacia y Seguridad de Satralizumab en la Distrofia Muscular de Duchenne (NCT06450639):** RECLUTANDO\n",
      "\n",
      "\n",
      "Es importante notar que el estado de \"activo\" puede variar rápidamente. Esta respuesta se basa en la información proporcionada y puede no reflejar la situación actual con total precisión. Para obtener la información más actualizada, se recomienda consultar directamente la base de datos de ClinicalTrials.gov.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 20:18:42,925 - INFO - El usuario ha finalizado la sesión.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Chau!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"cache\", exist_ok=True)\n",
    "    \n",
    "    if len(documentos) == 0:\n",
    "        print(\"No se cargaron documentos. Por favor, verifica el directorio 'data'.\")\n",
    "        logging.error(\"No se encontraron documentos. Finalizando.\")\n",
    "    else:\n",
    "        print(\"Bienvenido al Chatbot de Ensayos Clínicos\")\n",
    "        print(\"Conversemos sobre Ensayos Clínicos\\n de enfermedades neuromusculares: Distrofia Muscular de Duchenne o de Becker, Enfermedad de Pompe, Distrofia Miotónica, etc.\")\n",
    "        print(\"Escribí tu pregunta, indicando claramente la enfermedad sobre la que quieres información de ensayos clínicos. Escribe 'salir' para terminar.\")\n",
    "        while True:\n",
    "            pregunta = input(\"Tu pregunta: \").strip()\n",
    "            if pregunta.lower() in ['salir', 'chau', 'exit', 'quit']:\n",
    "                print(\"¡Chau!\")\n",
    "                logging.info(\"El usuario ha finalizado la sesión.\")\n",
    "                break\n",
    "            if es_saludo(pregunta):\n",
    "                respuesta_saludo = responder_saludo()\n",
    "                print(respuesta_saludo)\n",
    "                logging.info(\"Se detectó un saludo.\")\n",
    "                continue\n",
    "            \n",
    "            # Identificar la enfermedad (documento más relevante)\n",
    "            idn = doc_enfermedad(pregunta)\n",
    "            index = index_archivos[idn] if idn < len(index_archivos) else None\n",
    "            trozos = trozos_archivos[idn] if idn < len(trozos_archivos) else []\n",
    "\n",
    "            # Responder pregunta\n",
    "            respuesta = responder_pregunta(pregunta, index, trozos)\n",
    "            print(f\"Respuesta: {respuesta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
