{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 1: Verificar versión de Python**\n",
    "Se valida que la versión de Python sea la requerida.\n",
    "\n",
    "- **Líneas Clave:**\n",
    "  - Importación de librerías para verificar la versión (`sys`, `os`).\n",
    "  - Configuración de logging para advertencias y mensajes informativos.\n",
    "  - Comparación de la versión actual con la requerida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:50:58,267 - INFO - \n",
      "    **********************************************\n",
      "    ** Versión de Python compatible **\n",
      "    **********************************************\n",
      "    Python 3.10.12 detectado correctamente.\n",
      "    Todas las funcionalidades deberían operar sin problemas.\n",
      "    **********************************************\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Desactivar advertencias de paralelización en tokenizadores\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "\n",
    "# Versión requerida\n",
    "REQUIRED_VERSION = (3, 10, 12)\n",
    "current_version = sys.version_info\n",
    "\n",
    "# Validar compatibilidad de versión\n",
    "if (current_version.major, current_version.minor, current_version.micro) != REQUIRED_VERSION:\n",
    "    logging.warning(f\"\"\"\n",
    "    **********************************************\n",
    "    ** Advertencia: Versión de Python no compatible **\n",
    "    **********************************************\n",
    "    Este chatbot está optimizado para Python {REQUIRED_VERSION[0]}.{REQUIRED_VERSION[1]}.{REQUIRED_VERSION[2]}.\n",
    "    La versión actual es Python {current_version.major}.{current_version.minor}.{current_version.micro}.\n",
    "    Algunas funcionalidades pueden no funcionar correctamente.\n",
    "    **********************************************\n",
    "    \"\"\")\n",
    "else:\n",
    "    logging.info(\"\"\"\n",
    "    **********************************************\n",
    "    ** Versión de Python compatible **\n",
    "    **********************************************\n",
    "    Python 3.10.12 detectado correctamente.\n",
    "    Todas las funcionalidades deberían operar sin problemas.\n",
    "    **********************************************\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 2: Instalación de Paquetes Necesarios**\n",
    "Se listan las bibliotecas requeridas para el funcionamiento del chatbot.\n",
    "\n",
    "- **Líneas Clave:**\n",
    "  - Uso de `requirements.txt` para instalar dependencias.\n",
    "  - Listado de las principales bibliotecas usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.40.2)\n",
      "Requirement already satisfied: transformers in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.46.3)\n",
      "Requirement already satisfied: sentence_transformers in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.3.1)\n",
      "Requirement already satisfied: hnswlib in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.8.0)\n",
      "Requirement already satisfied: numpy<2.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: PyPDF2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: tenacity in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (8.5.0)\n",
      "Requirement already satisfied: llama-index in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.12.2)\n",
      "Requirement already satisfied: llama-index-llms-gemini in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-embeddings-gemini in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (4.67.1)\n",
      "Requirement already satisfied: unidecode in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.3.8)\n",
      "Requirement already satisfied: langdetect in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.0.9)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (3.1.43)\n",
      "Requirement already satisfied: packaging<25,>=20 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (13.9.4)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (6.4.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (18.1.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (4.25.5)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (5.5.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (10.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (5.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (0.26.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 3)) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 3)) (1.14.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.12.2)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (3.9.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 9)) (0.3.2)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-llms-gemini->-r requirements.txt (line 10)) (0.5.4)\n",
      "Requirement already satisfied: six in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from langdetect->-r requirements.txt (line 14)) (1.16.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (1.15.2)\n",
      "Requirement already satisfied: jinja2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: pydantic in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (2.9.2)\n",
      "Requirement already satisfied: google-api-python-client in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (2.154.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (0.6.4)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (2.36.0)\n",
      "Requirement already satisfied: google-api-core in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (2.23.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (1.25.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 2)) (2024.10.0)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (1.55.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.2.15)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (3.11.9)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: httpx in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (0.28.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.0.8)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (0.8.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: wrapt in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (0.6.7)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 9)) (0.1.5)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (0.0.26)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (5.1.0)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 9)) (0.5.15)\n",
      "Requirement already satisfied: joblib in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 9)) (1.4.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 1)) (2.18.0)\n",
      "Requirement already satisfied: sympy in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 3)) (1.13.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (24.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (0.2.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.18.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (2.4.4)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (2.6)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (0.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.22.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (2024.10.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: anyio in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (4.6.2.post1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (3.23.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (1.66.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (0.22.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.2->llama-index->-r requirements.txt (line 9)) (1.2.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini->-r requirements.txt (line 10)) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalar las bibliotecas necesarias desde el archivo requirements.txt\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 3: Importar Librerías y Configurar Logging**\n",
    "Importa todas las librerías necesarias y configura un sistema de logs.\n",
    "\n",
    "- **Líneas Clave:**\n",
    "  - Importación de librerías estándar (`os`, `json`, `logging`).\n",
    "  - Importación de librerías específicas (`hnswlib`, `sentence_transformers`).\n",
    "  - Configuración del sistema de logs.\n",
    "  - Carga de variables de entorno desde un archivo `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luciano/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-07 10:51:21,171 - INFO - Librerías importadas correctamente.\n",
      "2024-12-07 10:51:21,173 - INFO - Variables de entorno cargadas desde el archivo .env.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import hnswlib\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core.llms import ChatMessage\n",
    "import time\n",
    "import hashlib\n",
    "import random\n",
    "from langdetect import detect\n",
    "\n",
    "# Configuración de logs para imprimir todo en consola\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# Mensaje de confirmación de importación\n",
    "logging.info(\"Librerías importadas correctamente.\")\n",
    "\n",
    "# Cargar variables de entorno desde un archivo .env\n",
    "load_dotenv()\n",
    "logging.info(\"Variables de entorno cargadas desde el archivo .env.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 4: Cargar Documentos**\n",
    "Carga documentos desde archivos o directorios.\n",
    "\n",
    "- **Líneas Clave:**\n",
    "  - `load_documents`: Carga archivos de tipo `.txt`, `.json`, y `.pdf`.\n",
    "  - `extract_content`: Procesa el contenido de los documentos dependiendo de su tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:51:21,220 - INFO - Iniciando carga desde el directorio: data.\n",
      "2024-12-07 10:51:21,241 - INFO - Archivo 'resumenes_lupus.json' cargado correctamente.\n",
      "2024-12-07 10:51:21,245 - INFO - Archivo 'resumenes_duchenne.json' cargado correctamente.\n",
      "2024-12-07 10:51:21,249 - INFO - Archivo 'resumenes_pompe.json' cargado correctamente.\n",
      "2024-12-07 10:51:21,252 - INFO - Archivo 'resumenes_becker.json' cargado correctamente.\n",
      "2024-12-07 10:51:21,254 - INFO - Archivo 'resumenes_glycogen storage disease.json' cargado correctamente.\n",
      "2024-12-07 10:51:21,255 - INFO - Archivo 'resumenes_myotonic dystrophy.json' cargado correctamente.\n",
      "2024-12-07 10:51:21,256 - INFO - 6 documentos cargados.\n",
      "2024-12-07 10:51:21,256 - INFO - Se cargaron 6 documentos exitosamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_documents(source, is_directory=False):\n",
    "    \"\"\"\n",
    "    Carga documentos desde un archivo o directorio.\n",
    "    \n",
    "    Args:\n",
    "        source (str): Ruta al archivo o directorio.\n",
    "        is_directory (bool): Indica si la fuente es un directorio.\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de diccionarios con 'filename' y 'content'.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source):\n",
    "        logging.error(f\"La fuente '{source}' no existe.\")\n",
    "        raise FileNotFoundError(f\"La fuente '{source}' no se encontró.\")\n",
    "\n",
    "    loaded_files = []\n",
    "    if is_directory:\n",
    "        logging.info(f\"Iniciando carga desde el directorio: {source}.\")\n",
    "        for filename in os.listdir(source):\n",
    "            filepath = os.path.join(source, filename)\n",
    "            if os.path.isfile(filepath) and filepath.endswith(('.txt', '.json', '.pdf')):\n",
    "                content = extract_content(filepath)\n",
    "                if content:\n",
    "                    loaded_files.append({\"filename\": filename, \"content\": content})\n",
    "                    logging.info(f\"Archivo '{filename}' cargado correctamente.\")\n",
    "    else:\n",
    "        logging.info(f\"Iniciando carga del archivo: {source}.\")\n",
    "        content = extract_content(source)\n",
    "        if content:\n",
    "            loaded_files.append({\"filename\": os.path.basename(source), \"content\": content})\n",
    "            logging.info(f\"Archivo '{os.path.basename(source)}' cargado correctamente.\")\n",
    "\n",
    "    logging.info(f\"{len(loaded_files)} documentos cargados.\")\n",
    "    return loaded_files\n",
    "\n",
    "def extract_content(filepath):\n",
    "    \"\"\"\n",
    "    Extrae el contenido del archivo según su tipo.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Ruta al archivo.\n",
    "    \n",
    "    Returns:\n",
    "        list o dict o str: Contenido procesado del archivo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if filepath.endswith('.txt'):\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            units = content.split(\"\\n-----\\n\")\n",
    "            return units\n",
    "        elif filepath.endswith('.json'):\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            return data\n",
    "        elif filepath.endswith('.pdf'):\n",
    "            reader = PdfReader(filepath)\n",
    "            return ''.join(page.extract_text() or '' for page in reader.pages)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al extraer contenido de '{filepath}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Configuración de ruta y carga de documentos\n",
    "ruta_fuente = 'data'  # Asegúrate de tener una carpeta 'data' con los documentos\n",
    "documentos = load_documents(ruta_fuente, is_directory=True)\n",
    "logging.info(f\"Se cargaron {len(documentos)} documentos exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 5: Configurar la Clave API de Gemini**\n",
    "- Obtiene la clave API desde las variables de entorno.\n",
    "- Crea una instancia del modelo Gemini para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:51:22,262 - INFO - Gemini configurado correctamente.\n"
     ]
    }
   ],
   "source": [
    "gemini_llm = None\n",
    "\n",
    "def configure_gemini():\n",
    "    \"\"\"\n",
    "    Configura la instancia de Gemini usando la clave API.\n",
    "    \n",
    "    Returns:\n",
    "        Gemini: Instancia configurada del modelo Gemini.\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        logging.error(\"La clave API de Gemini no está configurada.\")\n",
    "        raise EnvironmentError(\"Configura GEMINI_API_KEY en tu archivo .env.\")\n",
    "    gemini = Gemini(api_key=api_key)\n",
    "    logging.info(\"Gemini configurado correctamente.\")\n",
    "    return gemini\n",
    "\n",
    "gemini_llm = configure_gemini()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 6: Configurar el Modelo de Embeddings**\n",
    "- Se utiliza SentenceTransformer para generar embeddings de texto.\n",
    "- `doc_enfermedad(pregunta)`: Determina el índice del documento más relevante \n",
    "  según la similitud con el nombre del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:51:22,300 - INFO - Use pytorch device_name: mps\n",
      "2024-12-07 10:51:22,301 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Precomputar los embeddings de los nombres de archivo para eficiencia\n",
    "archivos = [doc['filename'] for doc in documentos]\n",
    "archivos_embeddings = model.encode(archivos)\n",
    "\n",
    "def doc_enfermedad(pregunta):\n",
    "    \"\"\"\n",
    "    Identifica el índice del documento más relevante para la enfermedad en la pregunta.\n",
    "    Utiliza embeddings precomputados de los nombres de archivo.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "    \n",
    "    Returns:\n",
    "        int: Índice del documento más relevante.\n",
    "    \"\"\"\n",
    "    if not documentos:\n",
    "        logging.warning(\"No se encontraron documentos. Índice por defecto: 0.\")\n",
    "        return 0\n",
    "\n",
    "    # Generar embedding de la pregunta\n",
    "    preg_embedding = model.encode(pregunta)\n",
    "\n",
    "    # Calcular similitudes con los embeddings de los nombres de archivo\n",
    "    similarities = [util.cos_sim(preg_embedding, emb).item() for emb in archivos_embeddings]\n",
    "\n",
    "    # Obtener el índice con mayor similitud\n",
    "    max_index = similarities.index(max(similarities))\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 7: Crear Clases para Documentos e Índices**\n",
    "- Clase `Document`: Representa un documento con su texto y metadatos.\n",
    "- Clase `HNSWIndex`: Crea un índice para recuperación rápida de información mediante embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, text, metadata=None):\n",
    "        \"\"\"\n",
    "        Inicializa un documento con su contenido y metadatos.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Texto del documento.\n",
    "            metadata (dict, optional): Metadatos asociados al documento.\n",
    "        \"\"\"\n",
    "        self.page_content = text\n",
    "        self.metadata = metadata or {}\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Representación en string del documento.\n",
    "        \n",
    "        Returns:\n",
    "            str: Información formateada del documento.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f\"Título: {self.metadata.get('Title', 'N/A')}\\n\"\n",
    "            f\"Resumen: {self.metadata.get('Summary', 'N/A')}\\n\"\n",
    "            f\"Tipo de Estudio: {self.metadata.get('StudyType', 'N/A')}\\n\"\n",
    "            f\"Paises donde se desarrolla el estudio: {self.metadata.get('Countries', 'N/A')}\\n\"\n",
    "            f\"Fase en que se encuentra el estudio: {self.metadata.get('Phases', 'N/A')}\\n\"\n",
    "            f\"Identificación en ClinicaTrial: {self.metadata.get('IDestudio', 'N/A')}.\\n\\n\"\n",
    "        )\n",
    "\n",
    "class HNSWIndex:\n",
    "    def __init__(self, embeddings, metadata=None, space='cosine', ef_construction=200, M=16):\n",
    "        \"\"\"\n",
    "        Inicializa el índice HNSWlib con los embeddings proporcionados.\n",
    "        \n",
    "        Args:\n",
    "            embeddings (np.ndarray): Matriz de embeddings.\n",
    "            metadata (list, optional): Lista de metadatos asociados a cada embedding.\n",
    "            space (str, optional): Espacio métrico para HNSWlib.\n",
    "            ef_construction (int, optional): Parámetro ef para la construcción del índice.\n",
    "            M (int, optional): Parámetro M para HNSWlib.\n",
    "        \"\"\"\n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = hnswlib.Index(space=space, dim=self.dimension)\n",
    "        self.index.init_index(max_elements=embeddings.shape[0], ef_construction=ef_construction, M=M)\n",
    "        self.index.add_items(embeddings, np.arange(embeddings.shape[0]))\n",
    "        self.index.set_ef(50)  # Parámetro ef para consultas\n",
    "        self.metadata = metadata or []\n",
    "    \n",
    "    def similarity_search(self, query_vector, k=5):\n",
    "        \"\"\"\n",
    "        Realiza una búsqueda de los k vecinos más similares.\n",
    "        \n",
    "        Args:\n",
    "            query_vector (np.ndarray): Vector de consulta.\n",
    "            k (int, optional): Número de vecinos a buscar.\n",
    "        \n",
    "        Returns:\n",
    "            list: Lista de tuplas con metadatos y distancias.\n",
    "        \"\"\"\n",
    "        labels, distances = self.index.knn_query(query_vector, k=k)\n",
    "        return [(self.metadata[i], distances[0][j]) for j, i in enumerate(labels[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 8: Procesar Documentos y Crear Índices**\n",
    "- `desdobla_doc(data2)`: Crea objetos `Document` a partir del contenido.\n",
    "- Para JSON con ensayos clínicos, crea un `Document` por ensayo.\n",
    "- Para TXT/PDF, un `Document` genérico.\n",
    "- Genera embeddings y construye el índice `HNSWlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:53:50,003 - INFO - Índices HNSWlib creados para todos los documentos.\n"
     ]
    }
   ],
   "source": [
    "def desdobla_doc(data2):\n",
    "    \"\"\"\n",
    "    Desdobla el contenido del documento en varios `Document` con metadatos.\n",
    "    Maneja JSON (asumiendo estructura de ensayos clínicos) o texto/PDF genérico.\n",
    "    \n",
    "    Args:\n",
    "        data2 (dict): Diccionario con 'filename' y 'content'.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Lista de `Document` y instancia de `HNSWIndex`.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    summaries = []\n",
    "    contenido = data2['content']\n",
    "    \n",
    "    if isinstance(contenido, list):\n",
    "        for entry in contenido:\n",
    "            if isinstance(entry, dict):\n",
    "                nctId = entry.get(\"IDestudio\", \"\")\n",
    "                briefTitle = entry.get(\"Title\", \"\")\n",
    "                summary = entry.get(\"Summary\", \"\")\n",
    "                studyType = entry.get(\"StudyType\", \"\")\n",
    "                country = entry.get(\"Countries\", \"\")\n",
    "                overallStatus = entry.get(\"OverallStatus\", \"\")\n",
    "                conditions = entry.get(\"Conditions\", \"\")\n",
    "                phases = entry.get(\"Phases\", \"\")\n",
    "\n",
    "                # Crear resumen en inglés para consistencia interna\n",
    "                Summary = (\n",
    "                    f\"The study titled '{briefTitle}', of type '{studyType}', \"\n",
    "                    f\"investigates the condition(s): {conditions}. \"\n",
    "                    f\"Brief summary: {summary}. \"\n",
    "                    f\"Current status: {overallStatus}, taking place in {country}. \"\n",
    "                    f\"The study is classified under: {phases} phase. \"\n",
    "                    f\"For more info, search {nctId} on ClinicalTrials.\"\n",
    "                )\n",
    "                metadata = {\n",
    "                    \"Title\": briefTitle,\n",
    "                    \"Summary\": Summary,\n",
    "                    \"StudyType\": studyType,\n",
    "                    \"Countries\": country,\n",
    "                    \"Phases\": phases,\n",
    "                    \"IDestudio\": nctId\n",
    "                }\n",
    "                doc = Document(Summary, metadata)\n",
    "                documents.append(doc)\n",
    "                summaries.append(Summary)\n",
    "            else:\n",
    "                # Si no es dict, tratar la entrada como texto genérico\n",
    "                texto = str(entry)\n",
    "                metadata = {\"Summary\": texto}\n",
    "                doc = Document(texto, metadata)\n",
    "                documents.append(doc)\n",
    "                summaries.append(texto)\n",
    "    else:\n",
    "        # Texto genérico (PDF o TXT)\n",
    "        texto = str(contenido)\n",
    "        metadata = {\"Summary\": texto}\n",
    "        doc = Document(texto, metadata)\n",
    "        documents.append(doc)\n",
    "        summaries.append(texto)\n",
    "\n",
    "    if documents:\n",
    "        embeddings = model.encode([doc.page_content for doc in documents], show_progress_bar=False)\n",
    "        embeddings = np.array(embeddings).astype(np.float32)\n",
    "        vector_store = HNSWIndex(embeddings, metadata=[doc.metadata for doc in documents])\n",
    "    else:\n",
    "        vector_store = None\n",
    "\n",
    "    return documents, vector_store\n",
    "\n",
    "# Procesar todos los documentos y crear sus respectivos índices\n",
    "trozos_archivos = []\n",
    "index_archivos = []\n",
    "for i in range(len(documentos)):\n",
    "    trozos, index = desdobla_doc(documentos[i])\n",
    "    trozos_archivos.append(trozos)\n",
    "    index_archivos.append(index)\n",
    "\n",
    "logging.info(\"Índices HNSWlib creados para todos los documentos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 9: Traducir Preguntas y Respuestas**\n",
    "- `traducir(texto, idioma_destino)`: Usa Gemini para traducir el texto solicitado.\n",
    "- `generate_embedding(texto)`: Genera embeddings para la pregunta en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caché en memoria para embeddings de preguntas\n",
    "embedding_cache = {}\n",
    "\n",
    "# Caché en memoria para traducciones\n",
    "translation_cache = {}\n",
    "\n",
    "def traducir(texto, idioma_destino):\n",
    "    \"\"\"\n",
    "    Traduce texto al idioma especificado usando el modelo Gemini.\n",
    "    Usa caché para evitar traducciones repetidas.\n",
    "    \n",
    "    Args:\n",
    "        texto (str): Texto a traducir.\n",
    "        idioma_destino (str): Idioma de destino.\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto traducido o original si ya está en el idioma deseado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        idioma_origen = detect(texto)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al detectar el idioma: {e}\")\n",
    "        idioma_origen = \"unknown\"\n",
    "\n",
    "    if idioma_origen.lower() == idioma_destino.lower():\n",
    "        logging.info(\"El texto ya está en el idioma de destino. No se realiza traducción.\")\n",
    "        return texto\n",
    "\n",
    "    if (texto, idioma_destino) in translation_cache:\n",
    "        logging.info(f\"Traducción obtenida del caché para el texto: {texto}\")\n",
    "        return translation_cache[(texto, idioma_destino)]\n",
    "\n",
    "    start_time = time.time()\n",
    "    mensajes = [\n",
    "        ChatMessage(role=\"system\", content=\"Actúa como un traductor.\"),\n",
    "        ChatMessage(role=\"user\", content=f\"Por favor, traduce este texto al {idioma_destino}: {texto}\")\n",
    "    ]\n",
    "    try:\n",
    "        respuesta = gemini_llm.chat(mensajes)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logging.info(f\"Traducción completada en {elapsed_time:.2f} segundos.\")\n",
    "        traduccion = respuesta.message.content.strip()\n",
    "        translation_cache[(texto, idioma_destino)] = traduccion\n",
    "        return traduccion\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al traducir: {e}\")\n",
    "        return texto  # fallback\n",
    "\n",
    "def generate_embedding(texto):\n",
    "    \"\"\"\n",
    "    Genera un embedding para el texto utilizando el modelo de embeddings.\n",
    "    Usa caché para evitar recalcular embeddings de textos repetidos.\n",
    "    \n",
    "    Args:\n",
    "        texto (str): Texto para generar el embedding.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Embedding generado o vector de ceros en caso de fallo.\n",
    "    \"\"\"\n",
    "    if texto in embedding_cache:\n",
    "        logging.info(f\"Embedding obtenido del caché para el texto: {texto}\")\n",
    "        return embedding_cache[texto]\n",
    "    try:\n",
    "        embedding = model.encode([texto])\n",
    "        embedding_cache[texto] = embedding\n",
    "        logging.info(f\"Embedding generado para el texto: {texto}\")\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al generar el embedding: {e}\")\n",
    "        # Devuelve embedding vacío como fallback\n",
    "        return np.zeros((1, 384))\n",
    "\n",
    "def obtener_contexto(pregunta, index, trozos, top_k=50):\n",
    "    \"\"\"\n",
    "    Recupera los trozos de texto más relevantes para responder la pregunta.\n",
    "    Traduce la pregunta al inglés antes de buscar en el índice.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "        index (HNSWIndex): Índice de HNSWlib para buscar similitudes.\n",
    "        trozos (list): Lista de `Document` relacionados.\n",
    "        top_k (int, optional): Número de resultados a recuperar.\n",
    "    \n",
    "    Returns:\n",
    "        str: Contexto relevante concatenado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Traducir la pregunta al inglés\n",
    "        pregunta_en_ingles = traducir(pregunta, \"inglés\")\n",
    "        logging.info(f\"Pregunta traducida al inglés: {pregunta_en_ingles}\")\n",
    "\n",
    "        # Generar embedding de la pregunta traducida\n",
    "        pregunta_emb = generate_embedding(pregunta_en_ingles)\n",
    "        logging.info(\"Embedding generado para la pregunta.\")\n",
    "\n",
    "        # Buscar en el índice\n",
    "        results = index.similarity_search(pregunta_emb, k=top_k)\n",
    "        texto = \"\"\n",
    "        for entry in results:\n",
    "            resum = entry[0][\"Summary\"]\n",
    "            texto += resum + \"\\n\"\n",
    "\n",
    "        logging.info(\"Contexto relevante recuperado para la pregunta.\")\n",
    "        return texto\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al obtener el contexto: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 10: Generar Respuestas**\n",
    "- `categorizar_pregunta(pregunta)`: Usa palabras clave para clasificar la pregunta (ej: 'ensayo', 'tratamiento').\n",
    "- `generar_prompt(categoria, pregunta)`: Crea una instrucción específica según la categoría.\n",
    "- `generar_respuesta(pregunta, contexto, prompt_especifico)`: \n",
    "  - Envía el prompt y el contexto a Gemini.\n",
    "  - Traduce la respuesta al español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_pregunta(pregunta):\n",
    "    \"\"\"\n",
    "    Clasifica la pregunta en categorías basadas en palabras clave.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "    \n",
    "    Returns:\n",
    "        str: Categoría identificada.\n",
    "    \"\"\"\n",
    "    categorias = {\n",
    "        \"tratamiento\": [\"tratamiento\", \"medicación\", \"cura\", \"terapia\", \"fármaco\"],\n",
    "        \"ensayo\": [\"ensayo\", \"estudio\", \"prueba\", \"investigación\", \"trial\"],\n",
    "        \"resultado\": [\"resultado\", \"efectividad\", \"resultados\", \"éxito\", \"fracaso\"],\n",
    "        \"prevención\": [\"prevención\", \"previene\", \"evitar\", \"reducción de riesgo\"]\n",
    "    }\n",
    "    for categoria, palabras in categorias.items():\n",
    "        if any(palabra in pregunta.lower() for palabra in palabras):\n",
    "            return categoria\n",
    "    return \"general\"\n",
    "\n",
    "def generar_prompt(categoria, pregunta):\n",
    "    \"\"\"\n",
    "    Genera un prompt específico basado en la categoría de la pregunta.\n",
    "    \n",
    "    Args:\n",
    "        categoria (str): Categoría de la pregunta.\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "    \n",
    "    Returns:\n",
    "        str: Prompt generado.\n",
    "    \"\"\"\n",
    "    prompts = {\n",
    "        \"tratamiento\": f\"Proporciona información sobre tratamientos en ensayos clínicos relacionados con: {pregunta}.\",\n",
    "        \"ensayo\": f\"Describe los ensayos clínicos actuales relacionados con: {pregunta}.\",\n",
    "        \"resultado\": f\"Explica los resultados más recientes de ensayos clínicos sobre: {pregunta}.\",\n",
    "        \"prevención\": f\"Ofrece información sobre prevención y ensayos clínicos para: {pregunta}.\"\n",
    "    }\n",
    "    return prompts.get(categoria, \"Por favor, responde la pregunta sobre ensayos clínicos.\")\n",
    "\n",
    "def es_saludo(pregunta):\n",
    "    \"\"\"\n",
    "    Verifica si la pregunta del usuario es un saludo.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si es un saludo, False de lo contrario.\n",
    "    \"\"\"\n",
    "    saludos = [\"hola\", \"buen día\", \"buenas\", \"cómo estás\", \"cómo te llamas\", \"qué tal\", \"estás bien\", \"buenas tardes\", \"buenas noches\"]\n",
    "    return any(saludo in pregunta.lower() for saludo in saludos)\n",
    "\n",
    "def responder_saludo():\n",
    "    \"\"\"\n",
    "    Genera una respuesta aleatoria a un saludo.\n",
    "    \n",
    "    Returns:\n",
    "        str: Respuesta de saludo.\n",
    "    \"\"\"\n",
    "    saludos_respuestas = [\n",
    "        \"¡Hola! Estoy para ayudarte con información sobre ensayos clínicos. ¿En qué puedo asistirte hoy?\",\n",
    "        \"¡Buenas! Tenés alguna pregunta sobre ensayos clínicos en enfermedades neuromusculares?\",\n",
    "        \"¡Hola! ¿Cómo puedo ayudarte con tus consultas sobre ensayos clínicos?\"\n",
    "    ]\n",
    "    return random.choice(saludos_respuestas)\n",
    "\n",
    "def generar_respuesta(pregunta, contexto, prompt_especifico):\n",
    "    \"\"\"\n",
    "    Genera una respuesta usando el contexto proporcionado y un prompt específico.\n",
    "    Primero genera la respuesta en inglés, luego la traduce al español.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "        contexto (str): Contexto relevante recuperado.\n",
    "        prompt_especifico (str): Prompt adaptado a la categoría de la pregunta.\n",
    "    \n",
    "    Returns:\n",
    "        str: Respuesta generada en español.\n",
    "    \"\"\"\n",
    "    mensajes = [\n",
    "        ChatMessage(role=\"system\", content=\"Eres un experto médico.\"),\n",
    "        ChatMessage(role=\"user\", content=f\"{prompt_especifico}\\nContexto: {contexto}\\nPregunta: {pregunta}\")\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        respuesta = gemini_llm.chat(mensajes)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logging.info(f\"Respuesta generada en inglés en {elapsed_time:.2f} segundos.\")\n",
    "        # Traducir la respuesta al español\n",
    "        respuesta_en_espanol = traducir(respuesta.message.content, \"español\")\n",
    "        logging.info(\"Respuesta traducida al español.\")\n",
    "        return respuesta_en_espanol\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al generar la respuesta: {e}\")\n",
    "        return \"Lo siento, ocurrió un error al generar la respuesta.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 11: Función Principal para Responder Preguntas**\n",
    "- Utiliza caché para no recalcular respuestas idénticas.\n",
    "- Integra categorización, obtención de contexto y generación de respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_hash(pregunta):\n",
    "    \"\"\"\n",
    "    Genera un hash SHA-256 para una pregunta dada.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "    \n",
    "    Returns:\n",
    "        str: Hash generado.\n",
    "    \"\"\"\n",
    "    return hashlib.sha256(pregunta.encode('utf-8')).hexdigest()\n",
    "\n",
    "def obtener_respuesta_cacheada(pregunta):\n",
    "    \"\"\"\n",
    "    Obtiene una respuesta cacheada para una pregunta si existe.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "    \n",
    "    Returns:\n",
    "        str o None: Respuesta cacheada o None si no existe.\n",
    "    \"\"\"\n",
    "    hash_pregunta = generar_hash(pregunta)\n",
    "    archivo_cache = f\"cache/{hash_pregunta}.json\"\n",
    "    if os.path.exists(archivo_cache):\n",
    "        try:\n",
    "            with open(archivo_cache, \"r\", encoding='utf-8') as f:\n",
    "                datos = json.load(f)\n",
    "                return datos.get(\"respuesta\", None)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al leer el caché: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def guardar_respuesta_cacheada(pregunta, respuesta):\n",
    "    \"\"\"\n",
    "    Guarda una respuesta en caché para una pregunta dada.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "        respuesta (str): Respuesta generada.\n",
    "    \"\"\"\n",
    "    hash_pregunta = generar_hash(pregunta)\n",
    "    archivo_cache = f\"cache/{hash_pregunta}.json\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(archivo_cache), exist_ok=True)\n",
    "        with open(archivo_cache, \"w\", encoding='utf-8') as f:\n",
    "            json.dump({\"pregunta\": pregunta, \"respuesta\": respuesta}, f, ensure_ascii=False, indent=4)\n",
    "        logging.info(f\"Respuesta cacheada para la pregunta: '{pregunta}'\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al guardar la respuesta en caché: {e}\")\n",
    "\n",
    "def responder_pregunta(pregunta, index, trozos):\n",
    "    \"\"\"\n",
    "    Integra categorización, obtención de contexto y generación de respuesta.\n",
    "    Incluye manejo de caché para respuestas repetidas.\n",
    "    \n",
    "    Args:\n",
    "        pregunta (str): Pregunta del usuario.\n",
    "        index (HNSWIndex): Índice de HNSWlib para búsqueda de contexto.\n",
    "        trozos (list): Lista de `Document` relacionados.\n",
    "    \n",
    "    Returns:\n",
    "        str: Respuesta generada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if index is None or not trozos:\n",
    "            logging.warning(\"No se encontraron índices o trozos para esta pregunta.\")\n",
    "            return \"No se encontró información para responder tu pregunta.\"\n",
    "\n",
    "        # Verificar caché\n",
    "        respuesta_cacheada = obtener_respuesta_cacheada(pregunta)\n",
    "        if respuesta_cacheada:\n",
    "            logging.info(f\"Respuesta obtenida del caché para: '{pregunta}'\")\n",
    "            return respuesta_cacheada\n",
    "\n",
    "        # Categorizar la pregunta\n",
    "        categoria = categorizar_pregunta(pregunta)\n",
    "        logging.info(f\"Categoría de la pregunta: {categoria}\")\n",
    "\n",
    "        # Generar prompt específico\n",
    "        prompt_especifico = generar_prompt(categoria, pregunta)\n",
    "        logging.info(f\"Prompt específico: {prompt_especifico}\")\n",
    "\n",
    "        # Obtener contexto relevante\n",
    "        contexto = obtener_contexto(pregunta, index, trozos)\n",
    "        if not contexto.strip():\n",
    "            logging.warning(\"No se encontró contexto relevante.\")\n",
    "            respuesta = \"No pude encontrar información relevante para responder tu pregunta.\"\n",
    "            guardar_respuesta_cacheada(pregunta, respuesta)\n",
    "            return respuesta\n",
    "\n",
    "        # Generar la respuesta\n",
    "        respuesta = generar_respuesta(pregunta, contexto, prompt_especifico)\n",
    "\n",
    "        # Guardar la respuesta en caché\n",
    "        guardar_respuesta_cacheada(pregunta, respuesta)\n",
    "        return respuesta\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en el proceso de responder pregunta: {e}\")\n",
    "        return \"Ocurrió un error al procesar tu pregunta.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PASO 12: Interfaz CLI**\n",
    "Ofrece una interfaz de línea de comando para interactuar con el chatbot.\n",
    "\n",
    "- **Líneas Clave:**\n",
    "  - Espera una pregunta del usuario.\n",
    "  - Responde saludos.\n",
    "  - Detecta si el usuario quiere salir.\n",
    "  - Llama a `responder_pregunta()` con la información necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenido al chatbot de Ensayos Clínicos.\n",
      "Conversemos sobre Ensayos Clínicos relacionados con las siguientes enfermedades neuromusculares:\n",
      "- Distrofia Muscular de Duchenne o de Becker\n",
      "- Enfermedad de Pompe\n",
      "- Distrofia Miotónica\n",
      "- Enfermedad de almacenamiento de glucógeno\n",
      "Por favor, escribe tu pregunta indicando claramente la enfermedad sobre la que deseas información.\n",
      "Escribí 'salir' para terminar la conversación.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "2024-12-07 10:54:01,851 - INFO - Categoría de la pregunta: ensayo\n",
      "2024-12-07 10:54:01,851 - INFO - Prompt específico: Describe los ensayos clínicos actuales relacionados con: ¿Cuantos ensayos clínicos están activos actualmente para la Distrofia Muscular de Duchenne?.\n",
      "2024-12-07 10:54:04,263 - INFO - Traducción completada en 1.39 segundos.\n",
      "2024-12-07 10:54:04,264 - INFO - Pregunta traducida al inglés: How many clinical trials are currently active for Duchenne Muscular Dystrophy?\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "2024-12-07 10:54:04,587 - INFO - Embedding generado para el texto: How many clinical trials are currently active for Duchenne Muscular Dystrophy?\n",
      "2024-12-07 10:54:04,588 - INFO - Embedding generado para la pregunta.\n",
      "2024-12-07 10:54:04,597 - INFO - Contexto relevante recuperado para la pregunta.\n",
      "2024-12-07 10:54:10,558 - INFO - Respuesta generada en inglés en 5.96 segundos.\n",
      "2024-12-07 10:54:16,036 - INFO - Traducción completada en 5.46 segundos.\n",
      "2024-12-07 10:54:16,037 - INFO - Respuesta traducida al español.\n",
      "2024-12-07 10:54:16,039 - INFO - Respuesta cacheada para la pregunta: '¿Cuantos ensayos clínicos están activos actualmente para la Distrofia Muscular de Duchenne?'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: Basándome en la información proporcionada, hay **11 ensayos clínicos activos actualmente** para la Distrofia Muscular de Duchenne. Estos son:\n",
      "\n",
      "* **El Registro de Duchenne (NCT02069756):** RECLUTANDO\n",
      "* **Estudio a largo plazo y de extensión de DS-5141b en pacientes con Distrofia Muscular de Duchenne (NCT04433234):** ACTIVO, NO RECLUTANDO\n",
      "* **Registro de evaluación por video de la Distrofia Muscular de Duchenne (NCT05712447):** ACTIVO, NO RECLUTANDO\n",
      "* **Estudio de SRP-4045 (Casimersen) y SRP-4053 (Golodirsen) en participantes con Distrofia Muscular de Duchenne (DMD) (NCT02500381):** ACTIVO, NO RECLUTANDO\n",
      "* **AFFINITY DUCHENNE: Terapia génica RGX-202 en participantes con Distrofia Muscular de Duchenne (DMD) (NCT05693142):** RECLUTANDO\n",
      "* **Un estudio de Fase 3 de TAS-205 en pacientes con Distrofia Muscular de Duchenne (REACH-DMD) (NCT04587908):** ACTIVO, NO RECLUTANDO\n",
      "* **Un estudio de la terapia génica SGT-003 en la Distrofia Muscular de Duchenne (INSPIRE DUCHENNE) (NCT06138639):** RECLUTANDO\n",
      "* **Un estudio observacional que compara Delandistrogene Moxeparvovec con el estándar de atención en participantes con Distrofia Muscular de Duchenne (NCT06270719):** RECLUTANDO\n",
      "* **Un estudio de CAP-1002 en pacientes ambulatorios y no ambulatorios con Distrofia Muscular de Duchenne (NCT05126758):** RECLUTANDO\n",
      "* **Hidroterapia en la Distrofia Muscular de Duchenne (DMD) (NCT06445985):** RECLUTANDO\n",
      "* **NS-089/NCNP-02-201 en niños con Distrofia Muscular de Duchenne (DMD) (NCT05996003):** RECLUTANDO\n",
      "* **Estudio de seguridad, tolerabilidad, farmacodinamia, eficacia y farmacocinética de DYNE-251 en participantes con Distrofia Muscular de Duchenne aptos para el salto del exón 51 (NCT05524883):** RECLUTANDO\n",
      "* **Un estudio de PGN-EDO51 en participantes con Distrofia Muscular de Duchenne aptos para el tratamiento de salto del exón 51 (NCT06079736):** RECLUTANDO\n",
      "* **Un estudio abierto para evaluar la eficacia y seguridad de Satralizumab en la Distrofia Muscular de Duchenne (NCT06450639):** RECLUTANDO\n",
      "\n",
      "\n",
      "Es importante tener en cuenta que el estado de \"activo\" puede cambiar rápidamente. Esta respuesta refleja el estado al momento del análisis de los datos proporcionados. Para obtener la información más actualizada, se recomienda consultar directamente la base de datos de ClinicalTrials.gov.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 10:54:18,820 - INFO - El usuario ha finalizado la sesión.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Chau!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Crear directorio de caché si no existe\n",
    "    os.makedirs(\"cache\", exist_ok=True)\n",
    "    \n",
    "    if len(documentos) == 0:\n",
    "        print(\"No se cargaron documentos. Por favor, verificá el directorio 'data'.\")\n",
    "        logging.error(\"No se encontraron documentos. Finalizando.\")\n",
    "    else:\n",
    "        # Mensaje de bienvenida e instrucciones para el usuario.\n",
    "        print(\"Bienvenido al chatbot de Ensayos Clínicos.\")\n",
    "        print(\"Conversemos sobre Ensayos Clínicos relacionados con las siguientes enfermedades neuromusculares:\")\n",
    "        print(\"- Distrofia Muscular de Duchenne o de Becker\")\n",
    "        print(\"- Enfermedad de Pompe\")\n",
    "        print(\"- Distrofia Miotónica\")\n",
    "        print(\"- Enfermedad de almacenamiento de glucógeno\")\n",
    "        print(\"Por favor, escribe tu pregunta indicando claramente la enfermedad sobre la que deseas información.\")\n",
    "        print(\"Escribí 'salir' para terminar la conversación.\")\n",
    "        while True:\n",
    "            pregunta = input(\"Tu pregunta: \").strip()\n",
    "            if pregunta.lower() in ['salir', 'chau', 'exit', 'quit']:\n",
    "                print(\"¡Chau!\")\n",
    "                logging.info(\"El usuario ha finalizado la sesión.\")\n",
    "                break\n",
    "            if es_saludo(pregunta):\n",
    "                respuesta_saludo = responder_saludo()\n",
    "                print(respuesta_saludo)\n",
    "                logging.info(\"Se detectó un saludo.\")\n",
    "                continue\n",
    "            \n",
    "            # Identificar la enfermedad (documento más relevante)\n",
    "            idn = doc_enfermedad(pregunta)\n",
    "            index = index_archivos[idn] if idn < len(index_archivos) else None\n",
    "            trozos = trozos_archivos[idn] if idn < len(trozos_archivos) else []\n",
    "\n",
    "            # Responder la pregunta\n",
    "            respuesta = responder_pregunta(pregunta, index, trozos)\n",
    "            print(f\"Respuesta: {respuesta}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
